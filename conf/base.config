/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    sanger-tol/readmapping Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Increasing the number of CPUs often gives diminishing returns, so we increase it
    following a logarithm curve. Example:
        - 0 < value <= 1: start + step
        - 1 < value <= 2: start + 2*step
        - 2 < value <= 4: start + 3*step
        - 4 < value <= 8: start + 4*step
    In order to support re-runs, the step increase may be multiplied by the attempt
    number prior to calling this function.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// Modified logarithm function that doesn't return negative numbers
def positive_log(value, base) {
    if (value <= 1) {
        return 0
    } else {
        return Math.log(value)/Math.log(base)
    }
}

def log_increase_cpus(start, step, value, base) {
    return check_max(start + step * (1 + Math.ceil(positive_log(value, base))), 'cpus')
}


process {

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 3
    maxErrors     = '-1'

    // In this configuration file, we give little resources by default and
    // explicitly bump them up for some processes.
    // All rules should still increase resources every attempt to allow the
    // pipeline to self-heal from MEMLIMIT/RUNLIMIT.

    // Default
    cpus   = 1
    memory = { check_max( 50.MB * task.attempt, 'memory' ) }
    time   = { check_max( 30.min * task.attempt, 'time' ) }

    withName: 'SAMTOOLS_(CONVERT|FILTER)' {
        time   = { check_max( 1.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(FASTA)' {
        time   = { check_max( 2.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(STATS)' {
        // Actually less than 1 hour for PacBio HiFi data, but confirmed 3 hours for Hi-C
        time   = { check_max( 4.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(COLLATE|FASTQ|FIXMATE|FLAGSTAT|MARKDUP|MERGE|SORT|VIEW)' {
        time   = { check_max( 8.hour * task.attempt, 'time' ) }
    }

    withName: 'SAMTOOLS_(FLAGSTAT|IDXSTATS)' {
        memory = { check_max( 250.MB  * task.attempt, 'memory'  ) }
    }

    withName: 'SAMTOOLS_(STATS|VIEW)' {
        memory = { check_max( 1.GB  * task.attempt, 'memory'  ) }
    }

    withName: '.*:FILTER_PACBIO:SAMTOOLS_COLLATE' {
        cpus   = { log_increase_cpus(4, 2*task.attempt, 1, 2) }
        memory = { check_max( 1.GB  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
    }

    withName: 'SAMTOOLS_SORMADUP' {
        cpus   = { log_increase_cpus(2, 6*task.attempt, 1, 2) }
        memory = { check_max( 10.GB + 6.GB * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max( 2.h * Math.ceil( meta.read_count / 100000000 ) * task.attempt / log_increase_cpus(2, 6*task.attempt, 1, 2), 'time' ) }
    }

    withName: SAMTOOLS_SORT {
        cpus   = { log_increase_cpus(4, 2*task.attempt, 1, 2) }
        // Memory increases by 768M for each thread
        memory = { check_max( 1.GB + 800.MB * log_increase_cpus(4, 2*task.attempt, 1, 2), 'memory' ) }
        time   = { check_max(        8.hour * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'time' ) }
    }

    withName: BLAST_BLASTN {
        time   = { check_max(          2.hour  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'time'   ) }
        memory = { check_max( 100.MB + 20.MB   * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
        // The tool never seems to use more than 1 core even when given multiple. Sticking to 1 (the default)
    }

    withName: BWAMEM2_INDEX {
        memory = { check_max( 24.GB  * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max( 30.min * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'time'   ) }
        // Not multithreaded
    }

    withName: BWAMEM2_MEM {
        // Corresponds to 12 threads as the minimum, 24 threads if 3 billion reads
        cpus   = { log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2) }
        // Runtime for 1 billion reads on 12 threads is a function of the logarithm of the genome size
        // Runtime is considered proportional to the number of reads and inversely to number of threads
        time   = { check_max( 3.h * task.attempt *  Math.ceil(positive_log(meta2.genome_size/100000, 10)) * Math.ceil(meta.read_count/1000000000) * 12 / log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2), 'time' ) }
        // Memory usage for 1 BWAMEM2 thread is 500 MB for every 1 Gbp.
        // Memory usage of BWAMEM2 is about proportional to the number of threads but need to add about 6 GB to avoid MEMLIMIT.
        // Memory usage of SAMTOOLS_VIEW is negligible.
        memory = { check_max( 6.GB + 500.MB * Math.ceil(meta2.genome_size / 1000000000) * log_increase_cpus(6, 6*task.attempt, meta.read_count/1000000000, 2), 'memory' ) }
    }

    withName: MINIMAP2_ALIGN {
        cpus   = { log_increase_cpus(4, 2*task.attempt, meta.read_count/1000000, 2) }
        memory = { check_max( (6.GB * Math.ceil( reference.size()  / 1000000000 ) + 4.GB * Math.ceil( meta.read_count / 1000000 )) * task.attempt, 'memory' ) }
        time   = { check_max(        3.h  * Math.ceil( meta.read_count   / 1000000   ) * task.attempt, 'time'   ) }
    }

    withName:CUSTOM_DUMPSOFTWAREVERSIONS {
        cache = false
    }
}
