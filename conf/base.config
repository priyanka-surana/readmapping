/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    sanger-tol/readmapping Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 2
    maxErrors     = '-1'

    // In this configuration file, we give little resources by default and
    // explicitly bump them up for some processes.
    // All rules should still increase resources every attempt to allow the
    // pipeline to self-heal from MEMLIMIT/RUNLIMIT.

    // Default
    cpus   = 1
    memory = { check_max( 50.MB * task.attempt, 'memory' ) }
    time   = { check_max( 30.min * task.attempt, 'time' ) }

    // These SAMTOOLS processes can take more than 30 min, and sometimes several hours.
    // Let's give them 8 hours, which should be plenty of time.
    withName: 'SAMTOOLS_(COLLATE|CONVERT|FASTA|FASTQ|MERGE|STATS|VIEW)' {
        time   = { check_max( 8.hour * task.attempt, 'time' ) }
    }

    // A bit more memory for these SAMTOOLS.
    withName: 'SAMTOOLS_(FLAGSTAT|IDXSTATS|STATS|VIEW)' {
        memory = { check_max( 1.GB  * task.attempt, 'memory'  ) }
    }

    withName: '.*:FILTER_PACBIO:SAMTOOLS_COLLATE' {
        cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
        memory = { check_max( 1.GB  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
    }

    withName: 'SAMTOOLS_SORMADUP' {
        cpus   = { check_max(        8      * task.attempt, 'cpus'    ) }
        memory = { check_max( 6.GB + 2.GB   * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max(        6.hour * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'time' ) }
    }

    withName: SAMTOOLS_SORT {
        cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
        memory = { check_max( 4.GB + 2.GB * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max( 4.hour * Math.ceil( meta.read_count / 1000000000 ) * task.attempt, 'time' ) }
    }

    withName: BLAST_BLASTN {
        time   = { check_max(          2.hour  * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'time'   ) }
        memory = { check_max( 100.MB + 20.MB   * Math.ceil( meta.read_count / 1000000 ) * task.attempt, 'memory' ) }
        // The tool never seems to use more than 1 core even when given multiple. Sticking to 1 (the default)
    }

    withName: BWAMEM2_INDEX {
        memory = { check_max( 24.GB  * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'memory' ) }
        time   = { check_max( 20.min * Math.ceil( meta.genome_size / 1000000000 ) * task.attempt, 'time'   ) }
        // Not multithreaded
    }

    withName: BWAMEM2_MEM {
        memory = { check_max( 12.GB + 1.GB  * Math.ceil(24 *  Math.log(Math.ceil( meta2.genome_size / 1000000000 ))) * task.attempt, 'memory' ) }
        time   = { check_max(         1.min * Math.ceil( meta.read_count   / 1000000    ) * task.attempt, 'time'   ) }
        cpus   = { check_max( 8     + 4     * Math.ceil( meta.read_count   / 1000000000 ) * task.attempt, 'cpus' ) }
    }

    withName: MINIMAP2_ALIGN {
        memory = { check_max( (6.GB * Math.ceil( reference.size()  / 1000000000 ) + 4.GB * Math.ceil( meta.read_count / 1000000 )) * task.attempt, 'memory' ) }
        time   = { check_max(        3.h  * Math.ceil( meta.read_count   / 1000000   ) * task.attempt, 'time'   ) }
        cpus   = { check_max( 4    + 2    * Math.ceil( meta.read_count   / 1000000   ) * task.attempt, 'cpus' ) }
    }

    withName:CUSTOM_DUMPSOFTWAREVERSIONS {
        cache = false
    }
}
